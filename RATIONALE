Autograph pipelines / flow graphs:
___________________________________________

Related work: CnC-CUDA, Intel TBB

++ Resource allocation is managed automatically 
	The only reasonable choice to use the full capabilities of the underlying API
	No need to reason about temporary resources

-- Same as above
	The user may want to control precisely the resources/reuse them

++ Good optimization opportunities for temporally coherent pipelines 
	(when we do more or less the same thing on each frame)
	This is good for games, not so much for editors? maybe? 

++ can automatically extract parallelism

++ Synchronization/fencing is automatic and can be optimized

-- Becomes complex with pipelines depending on conditions
	Need higher-order nodes
-- No fine-grained user control over the scheduling of the operations
	i.e. cannot cull a branch of the flow graph manually 
-- Disruptive: forces FRP throughout the program

-- Difficult to model dependencies between successive draw operations 
	(especially when there is more than one operation)

++ Integrates well with GUI and interactive applications in general

Examples of optimizations:
+ Allocate precisely the correct number of render targets/textures (automatic ping-pong FBOs)
+ run two compute operations in parallel automatically (if there is more than one GPU/thread)
+ Automatic selection of storage memory based on the flow graph
+ Descriptor set optimization??

Proposition: a simpler set of primitives, implemented on top of autograph backends
=> no higher-order nodes (no conditionals)
=> individual pipelines, can temporarily deallocate their resources
=> more like a memory management technique


GLSL header gen
___________________________________________

Parse GLSL, generate C++ header file with type-safe bindings
One entry for each shader defined in the FX file

FX file: should it contain Blend/Depth/Rasterizer states?
VS #include ?


GPU promises and futures
___________________________________________

The rendering pipeline is dynamic. The individual rendering tasks are 
re-created on each frame.

-+ Resources must be managed manually
	Most notably: the residency of memory resources

-- Synchronization must be managed manually
	Although this is less painful with asynchronous primitives (promises and futures)

-- Hard to optimize for the backend API
	The backend does not have global knowledge of the rendering pipeline: 
	it cannot take advantage of the fact that the sequence of operations do not change
	between frames.
	As a result, must resort to caching and heuristics.
	=> how to take advantage of bindless/descriptor sets?

++ Integrates well with existing libraries
	No need for a complex machinery

-? Harder to make changes to an existing pipeline
	Not sure about this one: the only thing harder is that the user has to allocate 
	the new resources

++ parallel execution is explicitly controlled by the user

+? Barring complex pipeline optimizations that could not be done manually, probably more efficient as a whole

Ideas:

* Model GPU operations using asynchronous primitives (GPU-futures)
	
	// add command to command list for target
	draw(GPUAsync<Target>, state, bindings) -> GPUAsync<Target>

	GPUAsync A;
	GPUAsync B;

	// The order of these two operations is undefined!
	// They can even be done in parallel
	B = draw(A, something);
	draw(A, something else);

	// the correct way is:
	B = draw(A, something)
	C = draw(B, something)
	// which is rather verbose

	// but then you should be able to do things like:
	B = draw(A, something)
	C = draw(B, something)
	D = draw(C, B, ...)
	// and the system will automatically allocate a temporary render target
	// and synchronize on B
	// OR:
	// draw(X, ...) consumes its argument (takes a rvalue reference)
	// thus, the temporary copy is explicit
	// (this would work very well with Rust...)
	
	// extract the value of a GPU async with:
	GPUAsync<T> A;
	A.sync() -> T // forces CPU/GPU sync 
	// or you could chain a CPU asynchonous operation

	// IMO, this is more readable than the flow-graph approach
	// Especially concerning draw calls 
	// (need the concept of 'draw lists' with the flow-graph, to model 
	//  dependencies between a varying number of successive draw calls)
	// The resources can be GPUAsyncs too! (results of GPU operations)

* Multiple render targets?
	GPUAsync<Frame> has special members that can extract 
	a GPUAsync<Texture> from a render target

* Type-safe resource binding with variadic templates

* Type-safe shaders


Texture2D
Texture3D

Texture2DView<T, D> -> bindable as image or render target, but not as a texture
Texture2DView<const T, D> -> bindable as texture only

GPUAsync<Texture2D>().view() -> GPUAsync<Texture2DView>

Sampler -> ...



GPUAsync<T,D> 		: generic buffer of type T, living between the GPU and the CPU
//GPUAsync<TexturenD<T,D>,D> : specialization for texture types
GPUAsync<TexturenDView<T,D>,D> : specialization for texture view types
GPUAsync<Surface<D, T...>> : specialization for surfaces


GPUAsync<T&> or GPUAsync<array_ref<T>>

Problem with GPUAsync<array_ref<T>> : what if the size of the array is only known once the async operation is complete?

GPUAsync<array_ref<T>> specialization
- underlying buffer
- offset
- size in Ts


// should be:

GPUAsync<Surface<...>> v1 = context.getScreen();

v1 = draw(move(v1), ...)

	* move(v1)
	* draw(v1&&)
		* for each parameter
			* backend.bind(v1.detail, GPUAsync)
				* if the async object has an outstanding write command list, flush it
				* if the async object has pending read commands (is referenced by a command list somewhere)
				  and if we are writing to this object
				  	* fence on completion of read commands
				* add bind commands to detail.commandList (optimize redundancies)
		* add draw command to detail.commandList
		* copy v1 to result
		* return result 

Note: two GPUAsyncs can share the same command list
e.g. a texture_nd_view and a surface

-> question: when to drop the command list?
and when to allocate it?

v1 = draw(move(v1), ...)
...
v1 = draw(move(v1), ...)	// update v1


ShaderResource<T>	-> binds as an uniform buffer
ShaderResource<TexturenD<T>> -> gets a constant texture view, bind as texture with default linear sampler
ShaderResource<TextureUnit<TexturenD> > -> bind as texture unit + sampler pair
ShaderResource<TexturenDView > -> bind as image unit
ShaderResource<....> -> ....
ShaderResource<SSBO<...>> -> bind as SSBO (openGL specific)


XXX create multiple command lists in parallel?



// Drawables:
DrawIndexedMesh(Buffer<T>, Buffer<Index>)
DrawIndexedMesh(...)

Mesh(primitive type, buffers...)
IndexedMesh(primitive type, index buffer, buffers...)
InstancedMesh(primitive type, num instances, first instance, buffers...)
InstancedIndexedMesh(primitive type, num instances, first instance, index buffer, buffers...)

Buffer can be a buffer object or a view (GPUAsync<array_ref<T>>)

When to flush the command buffer?
when an async<surface> or async<texture> is joined?
Or immediately?

RAII and destructors:
- Destructor of the generic object is called
	backend.destroyXXX(object) is called
	detail objects are default-constructible and must not have a custom destructor?
	=> must be POD types

textures, surfaces, etc. are move-only types
surfaces do not own textures
but for convenience, there should be a way to create a surface without
first creating the underlying textures.
=> Use a ResourceScope as the owner of the data
	created object is bound to the scope

backend.createResourceScope(...)
backend.createFencedResourceScope(...)


Parallel operations:

1. v1 = compute(...)
2. v2 = compute(v1)
3. v3 = compute(v1)


2. v1 last written by CQ#1, no pending reads -> schedule on CQ#1
3. v1 last written by CQ#1, one pending read on CQ#1 -> schedule on CQ#2





About destructors and resource lifetimes
_____________________________

A common mistake:

	void thing(Device& d) 
	{
		auto param = Uniform(d, ...)
		draw(..., param, ...)
		// param drops here, but the draw operation may not have finished!
		// must extend the lifetime of param -> shared_ptr's ?
		// OR (gfx-rs): garbage-collect unused resources at end of frame (still using shared-ptrs)
		// OR: require the user to explicitly specify the lifetime of the source (using device.frame_scope.create<Uniform>())
	}

The lifetime of GPU resources are almost never tied to a function scope.
They live at least as long as the draw call, and maybe more if a reference to them is kept 
between frames.

Examples of scopes: 
	- lexical scope lifetime (almost never used)
	- object lifetime
	- frame lifetime
	- lifetime until fence
	- static lifetime

Once the scope object is destroyed, all objects bound to the scope become invalid
(but can still be destroyed)



About shaders
_____________________________

Nomenclature:
	Vertex shader (VS)
	Geometry shader (GS)
	Pixel shader (PS) -> Fragment shader
	Hull Shader (HS) -> Tess control
	Domain Shader (DS) -> Tess eval
	Compute Shader (CS)

do not expose individual objects

Shader resource types:

Textures (GL/D3D11)
Constant buffers (GL:uniforms/D3D11:cbuffers)
	UniformXXX binders
Read/write buffers (GL:SSBO/D3D11:RWBuffers)
	RWBuffer<T>, RWBufferSlot<T>, 
Read/write textures (GL:imagenD/D3D11:RWTexturenD)
	RWTexturenD<T>, RWTexturenDSlot<T>



About bindings
_____________________________

Divided in 3 parts:

	- Pipeline state object -> either PipelineState or ???
	- resources (textures, buffers, vertex buffers)
	- draw call parameters


Pipeline state:
	-> just pass a pipeline state object

Draw call:
	- MeshPart
	- DrawArrays
	- DrawIndexed
	- DrawIndexedInstanced
	- DrawIndirect

	TextureUnit(0, TextureType)
	BufferSlot(...)

* Upload texture data!

First simplification pass
_____________________________

* Blocking version of UploadBuffer::upload 
* kUniformBufferOffsetAlignment should be dynamically queried
* Upload buffers should return correctly aligned regions depending on the use
	Should not need to specify the alignment manaully
	-> explicitly typed buffers / tagged buffers 
* Normalize the order of template parameters (D, T...)
* Const-correctness in buffer and buffer slice types
	(buffer<const T> is immutable, buffer<T> is mutable and binds as a RWBuffer)
* Extract boilerplate for samples (pipeline creation, etc.)
	- common shaders
	- resource loading (meshes, textures)
	- common samplers
	- vertex types
	- rendering of meshes
* Force debug breakpoint
* Break on shader compilation error
* CRTP for the backend
* Bikeshedding: rename Backend to Driver
* Bikeshedding: snake_case names
* Simplify the passing of handles to backend functions
* pushDataToUploadBuffer is very poorly named

DONE Rename source files in backend
DONE Clean the samples boilerplate
DONE Use an unique cmake file for the samples
DONE Bikeshedding: lowercase file names
DONE Samples: automatically find the root asset folder
DONE Remove OpenGLPixelType.hpp
DONE Remove templated methods in backend (createTexturenD<TPixel>)
DONE Clean indentation (LLVM-style, 2 spaces)
DONE Remove refcounted resources



Formalization: usage of glm vector types
_____________________________

Minimum dependencies are always good. Consider removing glm from the requirements?
(so that people can use eigen instead)
Issue: cannot include predefined pixel types in the library. (except array types)
	=> that's good



Formalization: binders
_____________________________

Requirements in terms of concepts
	concept ShaderResource
	concept RenderTarget
	concept Drawable



Feature: type-erased texture types
_____________________________

Specialization of texturenD types
To be used when the pixel type is not known at compile time



Feature: multiDraw 
_____________________________


Feature: multiDrawIndirect
_____________________________


Feature: dispatchIndirect
_____________________________



Feature: clear/copy command
_____________________________

ag::clear
Clear textures, surfaces, buffers, etc.
Question: clear value should be raw bits or float[4]?
Facts about texture data:
	The layout of texture data is generally unknown. (tiling?)
	The driver or GPU must sometimes perform a conversion on upload.
	In general, there is no direct mapping between a pixel's color and a sequence of bits in texture data 
		(see compressed formats)
	Two types of conversion: 
		layout conversion (tiling) => opaque, GPU-specific
		format conversion (different pixel types) => avoid
	Possible format conversions vary between APIs, drivers and GPU

	For one texture format, 2 different associated types:
		- sample_type: interpolated/sampled pixel type
		- storage_type: type of elements in a texture 
			can be different from storage_type for compressed formats

Texture transfers:
glTexSubImage may copy the provided texture data to gl-managed memory and keep
it until the texture is ready to be copied over.
My guess is that D3D12, Vulkan and friends do no such thing (no extra memory allocations),
and we have to manage this "staging buffer" ourselves.

Layout of texture upload data:
Must follow alignment constraints (each scanline must be correctly aligned)
cf. PIXEL_UNPACK_ALIGNMENT

=> Need a special span type for correctly aligned image data
ImageData<T>, which is a view of an ImageBuffer<T>


Feature: Command lists
_____________________________

* For multithreaded command submission


Feature: Upload buffers
_____________________________

Currently hidden
* Expose upload buffers to the user?


Binders
_____________________________


// Shortcut draw binders (bind vertex buffers and emit the drawcall)
DrawArrays(PrimitiveType, vertex_source)
DrawIndexed(PrimitiveType, vertex_source, index_source)

// Base draw binders
DrawArrays(PrimitiveType, first, count)
DrawIndexed(PrimitiveType, first, count, base_vertex)

// Vertex buffers
VertexBuffer(vertex_buffer)
VertexBuffer(untyped_buffer, offset, stride)
IndexBuffer(buffer)
IndexBuffer(untyped_buffer, offset, type)




Feature: Compute pipelines and compute API
_____________________________

ag::compute(device, pipeline, <work group config>)


Feature: Render targets
_____________________________

Like binders, except for render targets:
Surface(tex0, tex1, ..., depth tex, stencil tex / depth-stencil tex)
Surface(TextureLayer(xxxx))
SurfaceCube(...)
TextureRT()
TextureLayerRT()
TextureCubeFaceRT()

draw(tex0, ...)
draw(Surface(tex_color, tex_depth), ...)
draw(screen, ...)
draw(tex_cube, ...)
draw(Surface(tex_color, tex_depth, tex_stencil))


Feature: D3D12 backend
_____________________________



Feature: Partially resident textures
_____________________________

Cool


Feature: Texture blit operations
_____________________________

Copy buffer data (with the same underlying type)
Copy texture data to another (with the same pixel type)
Copy texture data to RenderTarget? No: this is a rendering operation

ag::copy(commandlist, buffer_src, buffer_dst)
ag::copy(commandlist, texture_view_src, texture_view_dst)

Mappable buffer vs unmappable buffers
Mapped slices (accessible by the CPU) and buffer slices (not accessible by the GPU)
=> NO: hide mapped slices (they should only be WRITTEN by the CPU, not read)
=> access only through upload buffers

RawBuffer
Buffer<T>
Buffer<T[]>
RawBufferSlice
BufferSlice<T>
BufferSlice<T[]>
- MappedRawBufferSlice
- MappedBufferSlice<T>
- MappedBufferSlice<T[]>


Feature: Data readback
_____________________________

Needed!
Asynchronous VS synchronous
something like 
	texture.readBack([](auto view) {...})	// executed when the data is available. no syncing
or, for consistency, a free function:
	ag::readBack(commandlist, texture, [](auto view) {...})



Feature: Separate window creation from backend
_____________________________

Move these in separate libraries


Feature: graphics debugging and profiling
_____________________________

Record/replay frame



Feature: more texture types
____________________________

* Mip maps
* Cube maps
* texture arrays


Feature: GPU flow graphs
_____________________________

Intel TBB for the GPU
may require backend support 
(implement as an optional feature)


Feature: autograph-shaders
_____________________________

Shaders in C++ code (as lambdas), extracted by clang and transpiled to GLSL
Issue: host compiler, generation of correctly aligned data structures
At first: separate C++ code files (modularized)


Feature: extras
_____________________________

in namespace ag::extras, separate library

math: lightweight math support library
	ONLY: perspective transformations 

interactive: framework for interactive applications
	observables, reactive operations => use RxCpp
	application events: application close, etc.
	forward events (backend-specific) to input handlers, rendering contexts and windows
	not an extra!
        must provide escape hatches
        must be accessible by the application if needed
        => application creates the object, pass reference to ag subsystems
        => in charge of creating the main window

	application frameworks: 
		- GLFW
			using GraphicsDriver = OpenGLDriver
		- Native X11
			using GraphicsDriver = OpenGLDriver
		- Native Win32
			using GraphicsDriver = Win32GLDriver / DirectX11Driver / DirectX12Driver
                - WinRT
        naming: core? interactive?

input: library to handle various input devices
	mouses, keyboards, gamepads and graphics tablets
	input handlers receive events (opaque) from the application framework
	and translate them into input events
      (note: merge with ag::interactive)


mesh: generic mesh library
	use assimp for loading
	type-safe mesh types
	automatic normal generation
	smoothing groups
image_io: image loader, designed to be used easily with ag::Texturexx types
	depends on: stb_image? gli?
	image manipulation library? (video++ comes to mind)
text: draw text on a render target
	depends on freetype?
sdftext: signed distance field font rendering
	dependencies?
sprite: texture/sprite blitting operations
	no dependencies
postfx: post-process effects
	no dependencies
video: render video?
vector: vector drawing library (2D)
	nvg? 
	vector::draw(): extensions to ag::draw
visualization: visualizers/debuggers for various structures
	debug textures, structured buffers, meshes, etc.
	ex: draw mesh in wireframe
		draw mesh with its normals, tangents, etc.
gui: user interface
graph: graphs (histograms, plots, etc.)
scene: scene graph rendering?
shade_graph: load shader graphs and flow graphs from a description file
assets: asset management (load assets by key, cache resources)
ecs: entity-component system
pcg: procedural content generation utilities?
animation: animation curves, CPU/GPU skinning and skeletal animation
	use assimp to load motion files
terrain: heightmap rendering
canvas: digital painting canvas structures and operations
	- layers (dirty region management)
	- blend modes
	- brush engine
	- support for undo buffer
	- support for painting in texture maps
	(high priority)


Needed for canvas
_____________________________

Texture upload/download
Painter:

- Brush engine
	-> draw to stroke mask (pipeline)
	-> compose stroke (compute pipeline)

Brush(draw_pipeline, compose_pipeline, parameters)



Feature: event and input 
_____________________________

Based on observable objects
Observable object:
	Observable<T>
	can subscribe to changes
Events: fed to observables

One-way:
	signal -> receiver
Two-way:
	data binding

auto key_press_event = keyboard.onKey(Key::F1).map(Key::Pressed)

observables:
	raw mouse/pointer events (delta values)
	keyboard events
	mouse button events

published behaviors: 
	mouse button state
	mouse cursor position
